<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: nodejs | Alexander Beletsky's development blog]]></title>
  <link href="http://beletsky.net/blog/categories/nodejs/atom.xml" rel="self"/>
  <link href="http://beletsky.net/"/>
  <updated>2014-01-25T14:55:07+02:00</updated>
  <id>http://beletsky.net/</id>
  <author>
    <name><![CDATA[Alexander Beletsky]]></name>
    <email><![CDATA[alexander.beletsky@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Keeping Node.js Processes Running]]></title>
    <link href="http://beletsky.net/2014/01/keeping-node-dot-js-processes-running.html"/>
    <updated>2014-01-18T13:38:00+02:00</updated>
    <id>http://beletsky.net/2014/01/keeping-node-dot-js-processes-running</id>
    <content type="html"><![CDATA[<p>Node.js/Express.js is great for Web API&rsquo;s and applications. In contrast to known enterprise technologies, Node.js is very special. It&rsquo;s single process/threaded environment. In case of unhanded exception occurred Node.js virtual machine simply stops, leaving application in unresponsive state.</p>

<p>Due to <code>async</code> nature of Node.js <code>try/catch</code> not always works, even with <code>domains</code> and stuff you have a chance that application crashed on production while you sleep.</p>

<!-- More -->


<p>To mitigate the issue few <a href="http://stackoverflow.com/questions/1972242/auto-reload-of-files-in-node-js">known solutions</a> exist, common idea is that there is watchdog that keeping eye on <code>node</code> process and if crashed, restarts application again.</p>

<p>Recently I&rsquo;ve used great library by <a href="https://github.com/mafintosh">@mafintosh</a> called <a href="https://github.com/mafintosh/respawn">respawn</a>. I liked it&rsquo;s minimalistic style and decided to try it out.</p>

<p>The bare-bones code is very simple. Without modification of your application, just create file <code>monitor.js</code> with nearly such code:</p>

<p>```js
var respawn = require(&lsquo;respawn&rsquo;);</p>

<p>var monitor = respawn([&lsquo;node&rsquo;, &lsquo;server.js&rsquo;], {</p>

<pre><code>env: {ENV_VAR:'test'}, // set env vars
cwd: '.',              // set cwd
maxRestarts:10,        // how many restarts are allowed within 60s
sleep:1000,            // time to sleep between restarts
</code></pre>

<p>});</p>

<p>monitor.start(); // spawn and watch
```</p>

<p><code>monitor</code> will spawn new node process and in case of crash it will be restarted. You can also specify <code>maxRestars</code> (I recommend to do that, if something is really bad it won&rsquo;t be restarted infinitely) and <code>sleep</code> time.</p>

<p>I&rsquo;ve tried that, by implementing <code>/fail</code> end-point in my app, to see that <code>respawn</code> really works.</p>

<p>```js
app.get(&lsquo;/fail&rsquo;, function (req, res, next) {</p>

<pre><code>setTimeout(function () {
    var nu = null;
    nu.access();

    res.send('Hello World');
}, 1000);
</code></pre>

<p>});
```</p>

<p>if I try to hit <code>/fail</code> I&rsquo;ll see no results in browser, but if I go back to <code>/</code> the application is running in normal state.</p>

<p>But simple respawning of application is not complete solution. You need to know what exactly happened to be able to fix issue. <a href="http://beletsky.net/2013/07/think-ahead-think-logging.html">Proper logging</a> of your application is essential. I&rsquo;ll show my small setup around <code>respawn</code> that send critical message to <a href="https://logentries.com">Logentries</a>, so all crashes are logged.</p>

<p>```js
var respawn = require(&lsquo;respawn&rsquo;);
var util = require(&lsquo;util&rsquo;);
var logger = require(&lsquo;./source/utils/logger&rsquo;);</p>

<p>var proc = respawn([&lsquo;node&rsquo;, &lsquo;app.js&rsquo;], {</p>

<pre><code>cwd: '.',
maxRestarts: 10,
sleep: 1000,
</code></pre>

<p>});</p>

<p>proc.on(&lsquo;spawn&rsquo;, function () {</p>

<pre><code>util.print('application monitor started...');
</code></pre>

<p>});</p>

<p>proc.on(&lsquo;exit&rsquo;, function (code, signal) {</p>

<pre><code>logger.fatal({msg: 'process exited, code: ' + code + ' signal: ' + signal});
</code></pre>

<p>});</p>

<p>proc.on(&lsquo;stdout&rsquo;, function (data) {</p>

<pre><code>util.print(data.toString());
</code></pre>

<p>});</p>

<p>proc.on(&lsquo;stderr&rsquo;, function (data) {</p>

<pre><code>logger.error({msg: 'process error', data: data.toString()});
</code></pre>

<p>});</p>

<p>proc.start();
```</p>

<p>(details of logger you can find in this <a href="http://beletsky.net/2013/07/think-ahead-think-logging.html">post</a>)</p>

<p>All process output is goes to <code>stdout</code>, which is convinient for development, but in case of <code>stderr</code> or <code>exit</code> everything is logged to cloud and notification to <code>dev-team</code> sent.</p>

<p>It worked really nice, now I&rsquo;m not worry even if something bad happens on production, <code>respawn</code> will make sure that rest of users are not affected. As a developer you can much quicker found bug and push hotfix.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Several Processes in Docker Container]]></title>
    <link href="http://beletsky.net/2013/12/run-several-processes-in-docker-container.html"/>
    <updated>2013-12-27T14:15:00+02:00</updated>
    <id>http://beletsky.net/2013/12/run-several-processes-in-docker-container</id>
    <content type="html"><![CDATA[<p>What I like the most about <a href="">Docker</a> project is new opportunity to deploy and distribute software. Many times I&rsquo;ve been to situation when I wanted to play with some software and get exited about, but after I read installation manual my excitement totally gone. Non trivial applications, requires quite a lot dependencies: runtimes, libraries, databases.</p>

<p>With docker, the installation instruction got reduced to something like:</p>

<p><code>
$ docker pull vendor/package
$ docker run vendor/package
</code></p>

<p>Simply like that, forget about missing Java Runtime on your server. It suits perfectly for TCP/HTTP applications.</p>

<!-- More -->


<p>Being messing around <a href="https://github.com/seismolabs/seismo">Seismo</a> project I realized, I want to go exactly same way. Since it has few dependencies now, MongoDB and NodeJS &ndash; it should be easier to anyone to try it, even if they do not use that setup. I was happy to see, that GitHub currently offers great support for Docker. Namely, if you have repo with <code>Dockerfile</code> inside, each time you push the code, docker image got rebuild and pushed to public <a href="https://index.docker.io/">index</a>.</p>

<p>I&rsquo;ve created <code>Dockerfile</code> that would build up image, ready to have Seismo run inside.</p>

<p>```plain
FROM    ubuntu:latest</p>

<h1>Git</h1>

<p>RUN apt-get install -y git</p>

<h1>MongoDB</h1>

<p>RUN apt-key adv &mdash;keyserver hkp://keyserver.ubuntu.com:80 &mdash;recv 7F0CEB10
RUN echo &lsquo;deb <a href="http://downloads-distro.mongodb.org/repo/ubuntu-upstart">http://downloads-distro.mongodb.org/repo/ubuntu-upstart</a> dist 10gen&rsquo; | tee /etc/apt/sources.list.d/10gen.list
RUN dpkg-divert &mdash;local &mdash;rename &mdash;add /sbin/initctl
RUN ln -s /bin/true /sbin/initctl
RUN apt-get update
RUN apt-get install mongodb-10gen
RUN mkdir -p /data/db</p>

<h1>NodeJS</h1>

<p>RUN apt-get update &mdash;fix-missing &amp;&amp; apt-get upgrade -y
RUN apt-get install -y wget curl build-essential patch git-core openssl libssl-dev unzip ca-certificates
RUN curl <a href="http://nodejs.org/dist/v0.10.22/node-v0.10.22-linux-x64.tar.gz">http://nodejs.org/dist/v0.10.22/node-v0.10.22-linux-x64.tar.gz</a> | tar xzvf &ndash; &mdash;strip-components=1 -C &ldquo;/usr&rdquo;
RUN apt-get clean &amp;&amp; rm -rf /var/cache/apt/archives/<em> /var/lib/apt/lists/</em></p>

<h1>Seismo</h1>

<p>RUN git clone <a href="https://github.com/seismolabs/seismo.git">https://github.com/seismolabs/seismo.git</a> /seismo
RUN cd /seismo; npm install
ENV PORT 8080
EXPOSE 8080</p>

<p>WORKDIR /seismo
ENTRYPOINT [&ldquo;./bin/run.sh&rdquo;]
```</p>

<p>It&rsquo;s based on latest Ubuntu server, installs Git, MongoDB and NodeJS runtime and clones Seismo itself inside image.</p>

<p>But, I&rsquo;ve met a problem to start few processes inside the container. Since I need both MongoDB for storage and NodeJS for API server, it&rsquo;s required both be running inside one container. If shell script just starts one, <code>mongod</code> for example, <code>node app.js</code> is not executed.</p>

<p>I was a little worried, thinking it&rsquo;s not possible to run more that one process inside container.</p>

<p>But solution was found. I&rsquo;ve created another shell script that starts <code>mongod</code> as background process and starts <code>node</code> after.</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<p>mongod &amp; node ./source/server.js
```</p>

<p>That worked as charm.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Catch Errors in Express.js Application]]></title>
    <link href="http://beletsky.net/2013/10/catch-errors-in-express-dot-js-application.html"/>
    <updated>2013-10-18T09:56:00+03:00</updated>
    <id>http://beletsky.net/2013/10/catch-errors-in-express-dot-js-application</id>
    <content type="html"><![CDATA[<p>This is a small follow up for my <a href="http://beletsky.net/2013/10/securing-express-dot-js-http-endpoints.html">previous post</a>, using the same technique not for authorization, but rather for error handling.</p>

<p>Let&rsquo;s go back, to the problem. I want to handle all errors in my application. Instead of <code>res.send()</code> or <code>res.json()</code>, I want to have a middleware that handles everything by itself. It can be flexible, so I can put any kind of logic there, like logging etc.</p>

<p>It&rsquo;s very easy to archive with <em>patch the middleware</em> method.</p>

<!-- More -->


<p>Just like in previous case, <code>app.use()</code> won&rsquo;t work here. First, it would apply to every request. Second, error handling middleware have to placed last, <code>app.use()</code> won&rsquo;t guarantee that.</p>

<h2>Follow the style</h2>

<p>To get benefits of common error handling/logging code, you have to follow particular style. It&rsquo;s very simple, though.</p>

<p>Your last endpoint (middleware) function have to always receive <code>next()</code> callback parameter, all logs have to pass as first argument to that function. You should not send errors directly as <code>res.send(500, 'Error')</code>.</p>

<p>```js
app.get(&lsquo;/api/users/:id&rsquo;, function (req, res, next) {</p>

<pre><code>db.users.find({id: req.params.id}, function (err, user) {
    if (err) {
        return next({message: 'failed to query db', status: 500});
    }

    if (!user) {
        return next({message: 'user not found', status: 404});
    }

    res.json(user);
});
</code></pre>

<p>});
```</p>

<p>Please note, that it receives first argument.. and the function is only called, the we call <code>next()</code> with first parameter.</p>

<h2>Error handler middleware</h2>

<p>Let&rsquo;s define the function. Since HTTP API&rsquo;s are JSON based, it would just return the JSON response and status.</p>

<p>```js
function logErrors(err, req, res, next) {</p>

<pre><code>req.unhandledError = err;

var message = err.message;
var error = err.error || err;
var status = err.status || 500;

res.json({message: message, error: error}, status);
</code></pre>

<p>};
```</p>

<h2>Apply the patch</h2>

<p>Again, right after all routes are already defined, let&rsquo;s call <code>applyErrorLogging()</code>.</p>

<p>```js
// &hellip;</p>

<p>require(&lsquo;./source/api&rsquo;)(app);
require(&lsquo;./source/router&rsquo;)(app);</p>

<p>applyAuthentication(app, [&lsquo;/api&rsquo;]);
applyErrorLogging(app);                 // apply error handling here</p>

<p>// &hellip;
```</p>

<p>And <code>applyErrorLogging()</code> function,</p>

<p>```js
var middleware = require(&lsquo;../middleware&rsquo;);</p>

<p>function applyErrorLogging(app) {</p>

<pre><code>for (var verb in app.routes) {
    var routes = app.routes[verb];
    routes.forEach(patchRoute);
}

function patchRoute (route) {
    route.callbacks.push(middleware.errors.logErrors);
}
</code></pre>

<p>}</p>

<p>module.exports = applyErrorLogging;
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Securing Express.js HTTP Endpoints]]></title>
    <link href="http://beletsky.net/2013/10/securing-express-dot-js-http-endpoints.html"/>
    <updated>2013-10-15T21:54:00+03:00</updated>
    <id>http://beletsky.net/2013/10/securing-express-dot-js-http-endpoints</id>
    <content type="html"><![CDATA[<p>Once you implement HTTP API using Express.js, the security became the concern. There are a lot of different options and strategies, implementing security for API&rsquo;s. One of the latest I prefer is described <a href="https://github.com/alexanderbeletsky/backbone-express-spa#authorization-cors">here</a>.</p>

<p>Doesn&rsquo;t matter what the actual strategy is, you have to apply it somehow in your application. In general, HTTP API security goes down to authorization. Having a piece of information in HTTP request (either field in header or value in cookie), by checking one you can say, is this HTTP request authorized or not.</p>

<!-- More -->


<h2>Middleware</h2>

<p>Such type of job is ideal for middleware. In fact, you might have middleware function, that does authorization:</p>

<p>```js
function access(req, res, next) {</p>

<pre><code>checkAuthorization(req, function (err, authorized) {
    if (err || !authorized) {
        res.send({message: 'Unauthorized', status: 401});
    }

    next();
});

function checkAuthorization(req, callback) {
    // actual auth strategy goes here..
}
</code></pre>

<p>}
```</p>

<p>Of cause, it&rsquo;s simply possible to apply this function to each HTTP method in application, like</p>

<p>```js
function peopleApi(app) {</p>

<pre><code>app.get('/api/people',
    middleware.access,
    getPeople);

app.get('/api/people/:id',
    middleware.access,
    getPerson);

app.post('/api/people',
    middleware.access,
    postPerson);

// ...
</code></pre>

<p>}</p>

<p>module.exports = peopleApi;
```</p>

<p>but, it&rsquo;s really get annoying to do that all the time.. and it&rsquo;s easy to just forgot to secure endpoint. So, it&rsquo;s better to keep the code as clean as possible.</p>

<p>```js
function peopleApi(app) {</p>

<pre><code>app.get('/api/people',
    getPeople);

app.get('/api/people/:id',
    getPerson);

app.post('/api/people',
    postPerson);

// ...
</code></pre>

<p>}</p>

<p>module.exports = peopleApi;
```</p>

<p>That seems to be like <code>app.use()</code> is good candidate to place <code>access</code> function into, but it&rsquo;s not. <code>app.use()</code> is global apply of middleware function, so if applications serves static resources, that does not need authentication, or simply you want to expose some <strong>guest</strong> endpoints.</p>

<h2>Guest or not?</h2>

<p>Guest endpoints are ones, that can be accessed without authentication. That&rsquo;s a kind of special case, but typically required on any HTTP API projects I worked.</p>

<p>We need to distinguish between <strong>secure</strong> and <strong>guest</strong> endpoints. We&rsquo;ll introduce special middleware function, for guest access.</p>

<p>```js
function guest(req, res, next) {</p>

<pre><code>req.guestAccess = true;
next();
</code></pre>

<p>}</p>

<p>```</p>

<p>Now, assume that all endpoints are require authentication by default (which is good assumption), but ones that don&rsquo;t need to have <code>guest()</code> middleware be used.</p>

<p>```js
function peopleApi(app) {</p>

<pre><code>app.get('/api/people',
    getPeople);

app.get('/api/people/:id',
    getPerson);

app.post('/api/people',
    postPerson);

app.get('/api/people/meta',
    middleware.guest,               // no authentication required!
    getPeopleMeta);

// ...
</code></pre>

<p>}</p>

<p>module.exports = peopleApi;
```</p>

<h2>Patch the routes</h2>

<p>After I got a bit deeper with structure of Express.js <code>application</code> I came up to one idea that helped to solve the problem.</p>

<p>Then all endpoints are defined, <code>application</code> would contain initialized <a href="http://expressjs.com/api.html#app.routes">routes</a> object. If you look closer, then you&rsquo;ll see, besides of path and method data it also contains an array of <code>callbacks</code> applied to route. That&rsquo;s exactly middleware functions, so we can simply patch that array with authentication function we want.</p>

<p>The authentication function have to be called first, so it&rsquo;s need to be placed at first position of array.</p>

<p>Right after application configured and all routes are defined, call <code>applyAuthentication()</code> function.</p>

<p>```js
var app = express();</p>

<p>app.configure(function(){</p>

<pre><code>// configure
</code></pre>

<p>});</p>

<p>app.configure(&lsquo;development&rsquo;, function() {</p>

<pre><code>// configure for development
</code></pre>

<p>});</p>

<p>app.configure(&lsquo;production&rsquo;, function() {</p>

<pre><code>// configure for production
</code></pre>

<p>});</p>

<p>require(&lsquo;./source/api&rsquo;)(app);
require(&lsquo;./source/router&rsquo;)(app);</p>

<p>applyAuthentication(app, [&lsquo;/api&rsquo;]);     // apply authentication here</p>

<p>http.createServer(app).listen(app.get(&lsquo;port&rsquo;), function() {</p>

<pre><code>console.log('app listening on port ' + app.get('port'));
</code></pre>

<p>});
```</p>

<p>And finally, <code>applyAuthentication</code> function,</p>

<p>```js
var _ = require(&lsquo;underscore&rsquo;);
var middleware = require(&lsquo;../middleware&rsquo;);</p>

<p>function applyAuthentication(app, routesToSecure) {</p>

<pre><code>for (var verb in app.routes) {
    var routes = app.routes[verb];
    routes.forEach(patchRoute);
}

function patchRoute (route) {
    var apply = _.any(routesToSecure, function (r) {
        return route.path.indexOf(r) === 0;
    });

    var guestAccess = _.any(route.callbacks, function (r) {
        return r.name === 'guest';
    });

    if (apply &amp;&amp; !guestAccess) {
        route.callbacks.splice(0, 0, middleware.access.authenticatedAccess());
    }
}
</code></pre>

<p>}</p>

<p>module.exports = applyAuthentication;
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PaaS in Your Pocket with Dokku]]></title>
    <link href="http://beletsky.net/2013/09/paas-in-your-pocket-with-dokku.html"/>
    <updated>2013-09-16T21:21:00+03:00</updated>
    <id>http://beletsky.net/2013/09/paas-in-your-pocket-with-dokku</id>
    <content type="html"><![CDATA[<p>This is transcript of talk I gave on <a href="http://rejectjs.org/speakers.html#alexbeletsky">RejectJS</a> conf in Berlin, September 2013. Video is already available <a href="http://www.youtube.com/watch?v=EaoRDrdqm-E">here</a>.</p>

<p>What I&rsquo;m going to talk about is Dokku &ndash; pocket-size, very cool and interesting project, that would make you (hopefully) re-think of the code shipping.</p>

<!-- More -->




<script async class="speakerdeck-embed" data-id="d912a0f0fdbc0130260d1ebd49b9b82c" data-ratio="1.33333333333333" src="http://beletsky.net//speakerdeck.com/assets/embed.js"></script>


<h2>Background</h2>

<p>So, some background on me. My name is Alexander and I live in Kiev and work for Danish company, named E-conomic. There we do, we interesting product called Debitoor and a lot of cool stuff happens there.. But besides of that full-time job, with a friend of mine, I&rsquo;m doing a small project called Likeastore.</p>

<p>And this is exactly, side-project are something <strong>there you learn some new things and you try these things</strong>. So, it&rsquo;s started out as hackathon project, it&rsquo;s Node.js, MongoDB, Angular.js &ndash; so highly JS related thing (even if my talk is not so JS oriented). On a hackathon we got really exited on the way it went, soon we realized that we want to push things out. So, we wanted to release, and conquer the world with the cool idea we had.</p>

<p>Probably the most important lesson I&rsquo;ve learned in whole my career &ndash; the way you ship the code, matters!</p>

<p>It matters a lot, but the key fact &ndash; as faster you can ship the code from machine A to machine B, as faster you running business as happy team you have. So, if you shipping once a 2-weeks, you are fine, if you shipping 1-week are are great, if you shipping 1-per-hour you are superb (if you don&rsquo;t believe me, take a look on github guys, how happy they are all the time).</p>

<p>And long time I realized that deployment of code, should be as easy as:</p>

<p><code>
git push origin master
git push heroku master
af deploy
jitsu deploy
</code></p>

<p>Whatever, important is &ndash; one click (command, shell script) you are done.</p>

<p>So, we were seeking for good deployment and hosting options. And I love Node.js in particular for it&rsquo;s &ldquo;deployment-friendly&rdquo; environment.</p>

<p>Code deployment in general is very known developers problem. It solved many time and with cloud computing it <strong>evolutionized in something that&rsquo;s know as PaaS (platform as service)</strong>. And PaaS is something that brings a lot of value for any project, since you abstract out the exact infrastructure, and what you do is write code push it out, the rest is solved by PaaS.</p>

<p>Of cause, we started to look for PaaS that fits us best.</p>

<p>Started with AppFog, jumped to Nodejitsu, but met few constrains that forced us to gave up. Namely, that we had to have SSL connection, since we dealing with users private data, but Nodejitsu is proposing SSL for 120 USD that, simply too much of the project you begin with and don&rsquo;t have great budget behind.</p>

<p>I was really unhappy that time, since I realized a lot of overhead work that comes to you, then you drop PaaS.</p>

<p>This is where constraints coming from, and sometimes they are very unpleasant, but in general constraints are good. With perfect timing, I&rsquo;ve seen Dokku project.</p>

<p>Even if I said Dokku is small project, it&rsquo;s standing on shoulders of giants, and those giants are Docker &amp; Builtpacks &amp; Gitrecieve (there is a few more, but those are most important ones).</p>

<p>During this talk, I&rsquo;ll highlight both Docker and Dokku internals, but my primary goal is to rather share the <strong>experience of using Dokku that helped to making the things done</strong>.</p>

<h2>Dokku</h2>

<p>Dokku is created by bright hacker &ndash; Jeff Lindsay. And what Jeff did is he saw the opportunity of mixing all the pieces together in one tasty cocktail.</p>

<p>Dokku relying on Docker for running containers (as isolated application instance), it uses Gitrecive to implement git interface for server, and it&rsquo;s relying on Buildpacks, for preparing environment for container.</p>

<p>Now, it&rsquo;s time to show you how it works in reality:</p>

<p><code>
demo with node-sample
</code></p>

<h2>Gitrecieve</h2>

<p>Gitrecieve is a component which is able to recieve you git push command, create repository on fly and trigger recieve script. Recieve script could be anything you want.</p>

<h2>Buildpacks</h2>

<p>Buildpacks are open source components released by Heroku. How many of you guys ever used Heroku? All right, so the output you see, while pushing code to Heroku is exactly the <strong>result of work by Buildpack</strong>.</p>

<p>Buildpack is responsible for few things: it detects the environment of you app (like if I can see <code>package.json</code>, that would probably mean Node.js app), downloads all required runtime components and run build script. Once it run, we have created infrastructure where application is ready to start up.</p>

<p>So, Heroku created a lot of buildpacks, for Ruby, Python, Java, etc., and all that goodness is reused by Dokku.</p>

<h2>Docker</h2>

<p>How many of guys seen the videos, or read the materials about Docker? I hope many of you, because it&rsquo;s kind on noisy now.</p>

<p>So, Docker in essence, is the engine of <strong>portable containers</strong>. Portable? Containers? You are probably very interesting what actually goes, behind these words.</p>

<p>Docker is open-source project by dotCloud. And the dotCloud is actually specializing on shipping the code. Company&rsquo;s co-founder Salmon Hykes, gives are very nice metaphor on containers: imaging a shipping of goods like, 100 years ago &ndash; where were ships and barrels and bags and boxes, etc. Because of that variety you had a different options for shipping. In middle 1950, the idea of container born. Container defines size and dimensions, but in essence &ndash; you can put what ever you like there, close the door and that&rsquo;s it. It&rsquo;s guaranteed that you container is shipped, because all equipment fits it.</p>

<p>So, in dotCloud they&rsquo;ve developed a fairly complex infrastructure, that would allow to run their business. After 5 years of hacking that, they reached <strong>great level of expertise</strong>, as well they realized the need to take out the core system, rewrite it completely and open source it. That was then Docker project born and if Salmon would ever listen to my talk, I would like to give tons of Kudos for him, for that job.</p>

<p>Docker itself is hack above the Linux kernel technology called LXC. And LXC is the of running isolated processes. LXC is a Linux process, that have it&rsquo;s own file system, networking interfaces, processes etc.</p>

<p>Sure, you might think &ndash; it smells like virtual machines, why containers are better?</p>

<p>Image container is immutable entity. Once the command run, it&rsquo;s changed.. but as soon as change is not committed the image remain the same. That mean, you can re-use some existing image as many time as you want, all the time starting up, so called clean environment. The clean environment is something we like of using VM.</p>

<p>Startup time of container is <strong>many times faster, then booting up new VM image</strong>. And this is it&rsquo;s primary benefit.</p>

<p>Besides of that, Docker comes with so called Index. Index is a public repository of ready to use images. Different operations systems and different pre-installed software is there.</p>

<h2>Nginx</h2>

<p>All HTTP / HTTPS orchestration is done by Nginx.</p>

<h2>Deploying the applications with Dokku</h2>

<p>So, we&rsquo;ve came to the most interesting part, how Dokku is <strong>helpful for the product development</strong>. Theoretically, Dokku can work on any Linux machine with LXC support, to run docker, dokku itself is written on shell script, which make it really portable. Practically it works on Ubuntu 13 64b.</p>

<p>You build you own small PaaS on any IaaS as you want. One&rsquo;s which is able to fire up Ubuntu machine and give you ssh access to it. For a few reasons, I&rsquo;ve picked up Digital Ocean, since they indeed provide really nice service and competitive prices.</p>

<p>Once the machine is started, you push have to install Dokku there. After it&rsquo;s installed, you upload you SSH key there, so you are able to do git push.</p>

<p>You are able to configure environment variables, as well as configure SSL connection.</p>

<p>That&rsquo;s a <strong>perfect fit</strong>, especially for small projects.</p>
]]></content>
  </entry>
  
</feed>
