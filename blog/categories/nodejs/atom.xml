<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: nodejs | Alexander Beletsky's development blog]]></title>
  <link href="http://beletsky.net/blog/categories/nodejs/atom.xml" rel="self"/>
  <link href="http://beletsky.net/"/>
  <updated>2014-12-22T16:02:55+01:00</updated>
  <id>http://beletsky.net/</id>
  <author>
    <name><![CDATA[Alexander Beletsky]]></name>
    <email><![CDATA[alexander.beletsky@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Health Monitoring of Services and Databases]]></title>
    <link href="http://beletsky.net/2014/09/health-monitoring-of-http-services-and-databases.html"/>
    <updated>2014-09-19T18:27:00+02:00</updated>
    <id>http://beletsky.net/2014/09/health-monitoring-of-http-services-and-databases</id>
    <content type="html"><![CDATA[<p>Once you are up and running your primary job is to monitor that all your services are in good health. If something bad happens, network issue or crashes &ndash; you have to be notified on that as soon as possible. Hardering of the HTTP services and databases became a one of primary activities for any startup.</p>

<p>There few products on market that can do that, <a href="http://pingdom.com">Pingdom</a> and <a href="http://newrelic.com">New Relic</a> probably the most know. But they are paid and not that flexible as I want. So, I&rsquo;ve created <a href="https://github.com/likeastore/heartbeat">likeastore/heartbeat</a> that for a month or so helps me to provide quality service.</p>

<!-- MORE -->


<p>It&rsquo;s really easy to setup and deploy on any server or Dokku/Heroku environment.</p>

<h2>Overview</h2>

<p>The core of heartbeat is about ~300 <a href="https://github.com/likeastore/heartbeat/blob/master/source/hearbeat.js">lines of code</a>, so it&rsquo;s not a big deal to look inside to understand it principles of work. But in general, it&rsquo;s continuously running loop, that executes the small jobs who runs particular check strategy and report results if anything is wrong.</p>

<p>To make use of it you just need to clone the repo and update <a href="https://github.com/likeastore/heartbeat/blob/master/config/index.js">config/index.js</a> with your configuration.</p>

<h2>Notifications</h2>

<p>Heartbeat can use 2 types of notifications at the moment. <a href="https://mandrillapp.com/">Mandril</a> based emails and <a href="https://www.twilio.com/">Twilio</a> based SMSs.</p>

<p>Both requires you to create accounts there and provide API access keys.</p>

<p>That&rsquo;s what&rsquo;s configured on <a href="https://github.com/likeastore/heartbeat/blob/master/config/index.js#L67">transport</a> section of configuration:</p>

<p>```js
transport: {</p>

<pre><code>mandrill: {
    token: 'fake-token'
},

twilio: {
    sid: 'fake-sid',
    token: 'fake-token'
}
</code></pre>

<p>}
```</p>

<p>instead of <code>fake-token</code> and <code>fake-sid</code> you provide your real values there.</p>

<p>You have to specify the recipents for notifications, that happens in <a href="https://github.com/likeastore/heartbeat/blob/master/config/index.js#L56">notify</a> section of configuration:</p>

<p>```js
notify: {</p>

<pre><code>email: {
    from: 'heartbeat@likeastore.com',
    to: ['devs@likeastore.com']
},

sms: {
    to: ['+3805551211', '+3805551212']
}
</code></pre>

<p>}
```</p>

<p>As you can see, you specifying <code>from</code> and <code>to</code> emails, as well as <code>phone</code> numbers to send SMS.</p>

<h2>Monitoring</h2>

<p>Now the main part, configure monitoring options. The <a href="https://github.com/likeastore/heartbeat/blob/master/config/index.js#L10">monitor</a> section of configuration is responsible for that. At the moment, it provides provides 5 different monitoring strategies.</p>

<ul>
<li>HTTP</li>
<li>JSON</li>
<li>MongoDB</li>
<li>Ping</li>
<li>Resolve</li>
</ul>


<h3>HTTP</h3>

<p>The <code>HTTP</code> sends GET request to specified URL and checks the response code. If response code <code>!==200</code> the error notification is reported.</p>

<p>```js
<a href="http:">http:</a> [</p>

<pre><code>{
    url: 'https://likeastore.com'
},
{
    url: 'https://stage.likeastore.com'
}
</code></pre>

<p>]
```</p>

<p><code>http</code> is an array of urls to monitor.</p>

<h3>JSON</h3>

<p>The <code>JSON</code> strategy suits the best for HTTP API&rsquo;s. It could request particular URL receive JSON response and compare it to expected result.</p>

<p>```js
json: [</p>

<pre><code>{
    url: 'https://app.likeastore.com/api/monitor',
    response: {
        "app":"app.likeastore.com",
        "env":"production",
        "version":"0.0.52",
        "apiUrl":"/api"
    }
}
</code></pre>

<p>]
```</p>

<h3>MongoDB</h3>

<p>MongoDB is a commonly part of web applications infrastructure. You need to have a connection string and then you specify the checking query. It could be <code>find</code> query or <code>insert</code> query.</p>

<p>```js
mongo: [</p>

<pre><code>{
    connection: 'mongodb://localhost:27017/likeastoredb',
    collections: ['users'],
    query: function (db, callback) {
        db.users.findOne({email: 'alexander.beletsky@gmail.com'}, callback);
    }
}
</code></pre>

<p>]
```</p>

<h3>Resolve</h3>

<p>Resolve is something that makes <code>heartbeat</code> a little different. It usually the thing that one <code>domain names</code> is configured for different <code>ip addresses</code>. As it name stands, <code>resolve</code> would resolve all ip&rsquo;s associated with domain name and ping them separately. If even one of them fails, the notification is created.</p>

<p>```js
resolve: [</p>

<pre><code>{
    name: 'google.com'
}
</code></pre>

<p>]
```</p>

<p><code>nslookup</code> for <code>google.com</code> returns,</p>

<p>```plain
â€º nslookup google.com
Server:     192.168.1.1
Address:    192.168.1.1#53</p>

<p>Non-authoritative answer:
Name:   google.com
Address: 173.194.113.198
Name:   google.com
Address: 173.194.113.199
Name:   google.com
Address: 173.194.113.200
Name:   google.com
Address: 173.194.113.201
Name:   google.com
Address: 173.194.113.206
Name:   google.com
Address: 173.194.113.192
Name:   google.com
Address: 173.194.113.193
Name:   google.com
Address: 173.194.113.194
Name:   google.com
Address: 173.194.113.195
Name:   google.com
Address: 173.194.113.196
Name:   google.com
Address: 173.194.113.197
```</p>

<p>All that addresses will be checked separately.</p>

<h3>Ping</h3>

<p>Finally it&rsquo;s <code>ping</code>, the simples operation. It just pings given <code>ip</code> address.</p>

<p>```js
ping: [</p>

<pre><code>{
    ip: '37.139.9.95'
}
</code></pre>

<p>]
```</p>

<h2>Setting up the interval</h2>

<p>You can specify the interval of checking. By default it&rsquo;s 10 seconds, but you can do more frequent checks if you want.</p>

<p><code>js
interval: 5000
</code></p>

<h2>Running and deploying</h2>

<p>If the configuration is set, you can run heartbeat by,</p>

<p><code>bash
$ node app.js
</code></p>

<p>The log optionally could be forwared to <a href="logentries.com">Logentries</a>, by setting up <a href="https://github.com/likeastore/heartbeat/blob/master/config/index.js#L6">config/index.js#logentries</a> section.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Email, SMS and Push Notifications Server]]></title>
    <link href="http://beletsky.net/2014/08/notifier-email-sms-push-notifications.html"/>
    <updated>2014-08-22T15:38:00+02:00</updated>
    <id>http://beletsky.net/2014/08/notifier-email-sms-push-notifications</id>
    <content type="html"><![CDATA[<p>I recently came up with very convenient component &ndash; <a href="https://github.com/likeastore/notifier">likeastore/notifier</a>. Notifier is easy to setup Email, SMS and Push Notifications Server. It&rsquo;s been open sourced few month, very specific to <a href="https://likeastore.com">Likeastore</a> needs, but due to great <a href="https://github.com/likeastore/notifier/graphs/contributors">contributions</a> it became very generic and can be used in your projects as well.</p>

<p>Once you need to setup infrastructure for notifications in your application, it will be really easy to do. It provides transport of <a href="https://github.com/jimrubenstein/node-mandrill">Mandrill</a>, <a href="https://github.com/twilio/twilio-node">Twilio</a>, <a href="https://github.com/ToothlessGear/node-gcm">Android</a> and <a href="https://github.com/argon/node-apn">iOS</a> push notifications.</p>

<!-- MORE -->


<h2>Starting up</h2>

<p>The project already has comprehensive <a href="https://github.com/likeastore/notifier/blob/master/README.md">README</a> that explains initial steps. At the moment, the server is available as github repository that you need to clone and prepare entry point for it. I&rsquo;m thinking to pack the things into one <code>npm</code> module. If you see it makes sense, please let me know.</p>

<p>To start, you need to clone the repo,</p>

<p><code>bash
$ git clone https://github.com/likeastore/notifier.git
</code></p>

<p>And then create <code>app.js</code> file, there all setup of <code>notifer</code> taking place.</p>

<p>```js
var notifier = require(&lsquo;./source/notifier&rsquo;);</p>

<p>// TODO: configuration</p>

<p>// start the server
notifier.start(process.env.PORT || 7000);
```</p>

<p>Let&rsquo;s go straight to <code>configuration</code> part.</p>

<h2>Events, Actions and Executors</h2>

<p>The <code>notifier</code> is HTTP server, that receives <code>event</code> and turns that event into corresponding <code>action</code>. One event could create as many actions as needed. Actions is something that later is going to be <code>executed</code>.</p>

<p>The basic setup consits of 3 parts: receive event, resolve event and execute it.</p>

<p>```js
notifier</p>

<pre><code>.receive('incoming-event', function (event, actions, callback) { /* ... */ })
.resolve('created-action', function (action, actions, callback) { /* ... */ })
.execute('created-action', function (action, transport, callback) { /* ... */ });
</code></pre>

<p>```</p>

<p>Say, we have <code>user-registered</code> event which we need to send a welcome email,</p>

<p>```js
notifier</p>

<pre><code>.receive('user-registered', function (e, actions, callback) {
    actions.create('send-welcome', {user: e.user}, callback);
})
.resolve('send-welcome', function (action, actions, callback) {
    db.users.findOne({email: action.user}, function (err, user) {
        if (err) {
            return callback(err);
        }

        if (!user) {
            return callback({message: 'user not found', email: action.email});
        }

        var data = {
            email: action.user,
            user: _.pick(user, userPick)
        };

        actions.resolved(action, data, callback);
    });
})
.execute('send-welcome', function (action, transport, callback) {
    var vars = [
        {name: 'USERID', content: action.data.user._id},
        {name: 'USER_NAME', content: action.data.user.displayName || action.data.user.name}
    ];

    transport.mandrill('/messages/send-template', {
        template_name: 'welcome-email',
        template_content: [],
        message: {
            auto_html: null,
            to: [{email: action.data.email}],
            global_merge_vars: vars,
            preserve_recipients: false
        }
    }, callback);
});
</code></pre>

<p>```</p>

<ul>
<li><code>recieve</code> &ndash; receives event from outside and turns the event into corresponding action.</li>
<li><code>resolve</code> &ndash; step to extend action with additional data, email, name of user etc.</li>
<li><code>execute</code> &ndash; uses the transport to transmit the event</li>
</ul>


<h2>Transports</h2>

<p>Mandrill provides support from emails notifications,</p>

<p>```js
.execute(&lsquo;send-welcome&rsquo;, function (action, transport, callback) {</p>

<pre><code>var vars = [
    {name: 'USERID', content: action.data.user._id},
    {name: 'USER_NAME', content: action.data.user.displayName || action.data.user.name}
];

transport.mandrill('/messages/send-template', {
    template_name: 'welcome-email',
    template_content: [],
    message: {
        auto_html: null,
        to: [{email: action.data.email}],
        global_merge_vars: vars,
        preserve_recipients: false
    }
}, callback);
</code></pre>

<p>});
```</p>

<p>Twilio is used for sms,</p>

<p>```js
.execute(&lsquo;send-verify-sms&rsquo;, function (a, transport, callback) {</p>

<pre><code>    transport.twilio.messages.create({
        to: a.data.phone,
        from: '+12282201270',
        body: 'Verification code: 1111',
    }, callback);
});
</code></pre>

<p>```</p>

<p>For Android push notifications,</p>

<p>```js
.execute(&lsquo;send-android-push-notification&rsquo;, function (a, transport, callback) {</p>

<pre><code>var tokens = [];
tokens.push(a.data.token);

transport.android.push({
    message: {key1: 'value1', key2: 'value2'},
    tokens: tokens,
    retries: 3
}, callback);
</code></pre>

<p>});
```</p>

<p>For Apple push notifications,</p>

<p>```js
.execute(&lsquo;send-ios-push-notification&rsquo;, function (a, transport, callback) {</p>

<pre><code>var tokens = [];
tokens.push(a.data.token);

transport.ios.push({
    production: false, // use specific gateway based on 'production' property.
    passphrase: 'secretPhrase',
    alert: { "body" : "Your turn!", "action-loc-key" : "Play" , "launch-image" : "mysplash.png"},
    badge: 1,
    tokens: tokens
}, callback);
</code></pre>

<p>});
```</p>

<h2>Configuration</h2>

<p>Before the run, you need to make sure the <code>notifier</code> is configured properly. Security tokens and connections strings to MongoDB. If you use Logentries, you can provide token and all logs will be submitted there.</p>

<p>The <code>accessToken</code> is a shared secret between server and client, to prevent unauthorized access.</p>

<p>The <a href="https://github.com/likeastore/notifier/blob/master/config/production.config.js">config</a> is using ENV variables on production and hardcoded values for development and staging.</p>

<h2>Clients</h2>

<p><code>notifier</code> can be used by any HTTP client, in most simple case <code>curl</code>,</p>

<p><code>bash
$ echo '{"event": "incoming-event"}' | curl -H "Content-Type:application/json" -d @- http://notifier.likeastore.com/api/events?access_token=ACCESS_TOKEN
</code></p>

<p>We already have Node.js client <a href="https://github.com/DemocracyOS/notifier-client">DemocracyOS/notifier-client</a> and plan to have browser client as well. But in essence it&rsquo;s just HTTP post with <code>event</code> payload and <code>access_token</code> in query string, so basically it can be used from any language and platform.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Secure Deployment of ElasticSearch]]></title>
    <link href="http://beletsky.net/2014/07/secure-deployment-of-elasticsearch.html"/>
    <updated>2014-07-18T12:34:00+02:00</updated>
    <id>http://beletsky.net/2014/07/secure-deployment-of-elasticsearch</id>
    <content type="html"><![CDATA[<p>Remember my success <a href="http://beletsky.net/2014/05/got-tired-of-mongodb-full-text.html">story</a> of moving from MongoDB full text search index to <a href="http://www.elasticsearch.com">ElasticSearch</a>? After about one month of work our search service unexpectedly stopped. I received a bunch of emails from <a href="http://logentiries.com">Logentries</a> and <a href="http://newrelic.com">NewRelic</a> that server is no longer responsive.</p>

<p>Once I logged on to <a href="https://www.digitalocean.com/?refcode=de56d081b272">DigitalOcean</a> account, I&rsquo;ve seen message from administrators that server is sending a lot of traffic (UDP Flood), very likely compromised and therefore stopped. The link they give as <a href="https://www.digitalocean.com/community/questions/my-droplet-is-locked-by-support-staff-because-because-of-an-outgoing-flood-or-ddos-what-do-i-do">instructions</a> to fix the problem was quite comprehensive, but the most important info was in comments. A lot of people who were hit by problem had ElasticSearch deployed on their machines.</p>

<!-- MORE -->


<p>It appeared, if ES is left on default configuration with port opened outside, it will be easy target for bad guys, both of Java and ES vulnerability. Basically, I had to restore server from scratch, but this time I&rsquo;m not goint to be naive, server have to be properly secured.</p>

<p>I&rsquo;ll describe my setup that involves: Node.js, Dokku / Docker, SSL.</p>

<h2>Clean DigitalOcean image</h2>

<p>I had to reinstall my machine from scratch, so instead of creating plain Ubuntu 14 server, but I decided to go dokku/docker path. Something that I tried <a href="http://beletsky.net/2013/09/paas-in-your-pocket-with-dokku.html">before</a> and very happy with the <a href="http://beletsky.net/2013/08/digitalocean-plus-dokku-equals-10-heroku.html">results</a>. <a href="https://www.digitalocean.com/?refcode=de56d081b272">DigitalOcean</a> offers pre-packed image with dokku/docker already on board. As usually it takes just a few seconds to spin up machine on DO.</p>

<p>The plan was the following: deploy ElasticSearch instance inside Docker container, disable dynamic script features of Elastic, deploy Node.js based proxy server with custom authentication by Dokku and link those containers, so only Node.js proxy will have access to Elastic. Finally, all traffic between will by crypted by SSL.</p>

<p>The benefits are obvious, no more <code>:9200</code> is outside the machine, one potential vulnerability with dynamic script feature is disabled, only authenticated client could access Elastic server.</p>

<h2>Deployment of ElasticSearch in Docker</h2>

<p>First we need to have Docker image of ElasticSearch. There few ES plugging for Dokku, I decided to install one by myself, since I thought it is easier to configure. There is a great instruction from Docker <a href="https://registry.hub.docker.com/u/dockerfile/elasticsearch/">here</a>.</p>

<p><code>bash
$ docker pull docker pull dockerfile/elasticsearch
</code></p>

<p>Once the image is there, we need to prepare volume there Elastic stores data and configuration.</p>

<p><code>bash
$ cd /
$ mkdir elastic
</code></p>

<p>Elastic folder should contain <code>elasticsearch.yml</code> file, with all required configurations. My case is very simple, I have a cluster of one machine, so default configuration applies to me. One thing, that I mentioned above &ndash; I need to disable dynamic scripting features.</p>

<p><code>bash
$ nano elasticsearch.yml
</code></p>

<p>The content of the file is just one string,</p>

<p><code>plain
script.disable_dynamic: true
</code></p>

<p>Once it&rsquo;s done, we are ready to launch the server inside Docker container. Since, it could be done few times (during configuration and debugging), I&rsquo;ve created a small shell script,</p>

<p><code>bash
docker run --name elastic -d -p 127.0.0.1:9200:9200 -p 127.0.0.1:9300:9300 -v /elastic:/data dockerfile/elasticsearch /elasticsearch/bin/elasticsearch -Des.config=/data/elasticsearch.yml
</code></p>

<p>Please note the important thing, <code>-p 127.0.0.1:9200:9200</code> &ndash; here we are binding <code>:9200</code> to be only accessible on <code>localhost</code>. I&rsquo;ve spend some hours to close <code>:9200</code> by <code>iptables</code> without any success, but that thing works as expected. Thanks a lot to <a href="https://twitter.com/darkproger">@darkproger</a> and <a href="https://twitter.com/kkdoo">@kkdoo</a> for great help.</p>

<p><code>-v /elastic:/data</code> will map the containers volume <code>/data</code> to local one <code>/elastic</code>.</p>

<h2>Front-end Node.js server</h2>

<p>Now, we need to deploy front-end proxy server. It would proxy all traffic from <code>http://localhost:9200</code> into outside world, securely. I&rsquo;ve created small project, based on <a href="https://github.com/nodejitsu/node-http-proxy">http-proxy</a> called <a href="https://github.com/likeastore/elastic-proxy">elastic-proxy</a>. It&rsquo;s very simple one and can be easily re-used.</p>

<p><code>bash
$ git clone https://github.com/likeastore/elastic-proxy
$ cd elastic-proxy
</code></p>

<p>The server itself,</p>

<p>```js
var http = require(&lsquo;http&rsquo;);
var httpProxy = require(&lsquo;http-proxy&rsquo;);
var url = require(&lsquo;url&rsquo;);</p>

<p>var config = require(&lsquo;./config&rsquo;);
var logger = require(&lsquo;./source/utils/logger&rsquo;);</p>

<p>var port = process.env.PORT || 3010;
var proxy = httpProxy.createProxyServer();</p>

<p>var parseAccessToken = function (req) {</p>

<pre><code>var request = url.parse(req.url, true).query;
var referer = url.parse(req.headers.referer || '', true).query;

return request.access_token || referer.access_token;
</code></pre>

<p>};</p>

<p>var server = http.createServer(function (req, res) {</p>

<pre><code>var accessToken = parseAccessToken(req);

logger.info('request: ' + req.url + ' accessToken: ' + accessToken + ' referer: ' + req.headers.referer);

if (!accessToken || accessToken !== config.accessToken) {
    res.statusCode = 401;
    return res.end('Missing access_token query parameter');
}

proxy.web(req, res, {target: config.target, rejectUnauthorized: false});
</code></pre>

<p>});</p>

<p>server.listen(port, function () {</p>

<pre><code>logger.info('Likeastore Elastic-Proxy started at: ' + port);
</code></pre>

<p>});
```</p>

<p>It proxies all the requests and only by-pass ones, who provide <code>access_token</code> as query parameter. The <code>access_token</code> value is <a href="https://github.com/likeastore/elastic-proxy/blob/master/config/production.config.js">configured</a> on server, by applications environment variable <code>PROXY_ACCESS_TOKEN</code>.</p>

<p>As you already <a href="https://www.digitalocean.com/community/tutorials/how-to-use-the-dokku-one-click-digitalocean-image-to-deploy-a-python-flask-app">prepared</a> Dokku all you need to do is to push application to your server.</p>

<p><code>bash
$ git push master production
</code></p>

<p>After the deployment, you should go to server to configure applications environment,</p>

<p><code>bash
$ dokku config proxy set PROXY_ACCESS_TOKEN="your_secret_value"
</code></p>

<p>I wanted to have SSL and it&rsquo;s very easy to configure with Dokku. Just place your <code>server.crt</code> and <code>server.key</code> to <code>/home/dokku/proxy/tls</code> folder.</p>

<p>Proxy have to be <a href="https://github.com/scottatron/dokku-rebuild">redeployed</a> afterward, to apply configuration changes. Try proxy by hitting it&rsquo;s URL, in my case <a href="https://search.likeastore.com">https://search.likeastore.com</a>. If everything is good, it will reply,</p>

<p><code>plain
Missing access_token query parameter
</code></p>

<h2>Link containers</h2>

<p>We need to link both containers, so Node.js application is able to access ElasticSeach container. I really liked <a href="https://github.com/rlaneve/dokku-link">dokku-link</a> plugin, that does exactly that&rsquo;s required in very easy way. So, will install it</p>

<p><code>bash
$ cd /var/lib/dokku/plugins
$ git clone https://github.com/rlaneve/dokku-link
</code></p>

<p>Now, we need to link containers,</p>

<p><code>bash
$ dokku link proxy elastic
</code></p>

<p>And application have to be redeployed again. If everything is good, you will be able to access the server by <code>https://proxy.yourserver.com?access_token=your_secret_value</code> and see the response from ElasticSearch,</p>

<p>```js
{</p>

<pre><code>status: 200,
name: "Tundra",
version: {
    number: "1.2.1",
    build_hash: "6c95b759f9e7ef0f8e17f77d850da43ce8a4b364",
    build_timestamp: "2014-06-03T15:02:52Z",
    build_snapshot: false,
    lucene_version: "4.8"
},
tagline: "You Know, for Search"
</code></pre>

<p>}
```</p>

<h2>Reconfigure the client</h2>

<p>Depending on a client you use, you need to apply a little tweak to configuration. Basically, we need to use <code>access_token</code> for all our request. For Node.js applications,</p>

<p>```js
var client = elasticsearch.Client({</p>

<pre><code>host: {
    protocol: 'https',
    host: 'search.likeastore.com',
    port: 443,
    query: {
        access_token: process.env.ELASTIC_ACCESS_TOKEN
    }
},
requestTimeout: 5000
</code></pre>

<p>});
```</p>

<p>Again, <code>ELASTIC_ACCESS_TOKEN</code> is env variable to hold <code>your_secret_value</code> token.</p>

<p>Now, restart the application, make sure everything is running and exhale.</p>

<p><strong>PS</strong>. I would like to say thank to <a href="https://www.digitalocean.com/?refcode=de56d081b272">DigitalOcean</a> for support and a little credit I received as downtime compensation. Thats awesome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integration or Unit Tests Trade-Off]]></title>
    <link href="http://beletsky.net/2014/04/integration-tests-for-express-dot-js-middleware.html"/>
    <updated>2014-04-23T11:19:00+02:00</updated>
    <id>http://beletsky.net/2014/04/integration-tests-for-express-dot-js-middleware</id>
    <content type="html"><![CDATA[<p>Recently, I&rsquo;ve released small Express.js extension for easy switching application to <code>maintenance</code> mode. Sometimes, you just want to run patch against database or change the infrastructure of product, but instead of showing blank <code>nginx</code> 503 error page, you want to have nice looking HTML, saying will be back soon.</p>

<p>The <code>maintenance</code> package is now available on <a href="https://www.npmjs.org/package/maintenance">npm</a> and you welcome to use it. But I would like to share the way I developed and test it.</p>

<!-- More -->


<p>So, <code>maintenance</code> is a function that takes <code>app</code> instance and <code>options</code> as a parameters. Then it augments <code>app</code> with additional endpoint (if there is such preference) and injects middleware function that would render maintenance page in case of mode is set to <code>true</code>.</p>

<p>It&rsquo;s really small piece functionality, but still I wanted to make sure, it&rsquo;s gonna work in my application without annoying restarts of servers and debugging the stuff. And TDD is right approach to solve the pain.</p>

<p>TDD is quite commonly trade-off of <code>unit tests</code> and <code>integration tests</code>. And it&rsquo;s always up to developer which direction go in particular case. Let&rsquo;s take a look on my case:</p>

<p>If you go <code>unit test</code> way, it would be something like that:</p>

<ul>
<li>call <code>maintenance</code> function, pass mock of <code>express</code> instance

<ul>
<li>verify that new <code>route</code> is added after function completes</li>
<li>verify that all <code>route.callbacks</code> now have callback to check the mode</li>
<li>verify that <code>route.callbacks[0]</code> contains mode check function</li>
</ul>
</li>
<li>call <code>route.callbacks[0]</code>, mock <code>req</code> and <code>res</code> object

<ul>
<li>verify that <code>res.render</code> called with <code>maintanance.html</code> argument</li>
<li>etc..</li>
</ul>
</li>
</ul>


<p>Is all of that kind of <strong>suck</strong>? It is, since it would take too much effort for mocking the stuff.. But more important, all of that is nothing more as just testing of <strong>implementation details</strong> of Express.js, but not <strong>behavior details</strong> of application.</p>

<p>Now, let&rsquo;s consider <code>integration tests</code> way for same stuff:</p>

<ul>
<li>run application in normal mode

<ul>
<li>send HTTP GET and make sure that response is fine</li>
</ul>
</li>
<li>run application is maintenance mode

<ul>
<li>send HTTP GET and make sure that response contains maintenance page</li>
</ul>
</li>
<li>run application in normal mode

<ul>
<li>send HTTP GET and make sure that response is fine</li>
<li>sent HTTP POST to maintenance endpoint</li>
<li>send HTTP GET and make sure that response contains maintenance page</li>
</ul>
</li>
</ul>


<p>Does it look like real <strong>behavior</strong> testing? Indeed, test acts as <code>user</code> and checks that application actually behaves right, doesn&rsquo;t matter of implementation details.</p>

<p>With spending more time with Express.js and Node.js I see much <a href="http://beletsky.net/2014/03/testable-apis-with-node-dot-js.html">more value</a> in integration way of testing. It&rsquo;s very easy to spin-up a server and send HTTP requests and check responses.</p>

<p>If you are interested, check out <a href="https://github.com/likeastore/maintenance/blob/master/test/spec/maintenence.spec.js">specification</a> and <a href="https://github.com/likeastore/maintenance/blob/master/test/app/app.js">test application</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testable API's with Node.js]]></title>
    <link href="http://beletsky.net/2014/03/testable-apis-with-node-dot-js.html"/>
    <updated>2014-03-04T15:36:00+01:00</updated>
    <id>http://beletsky.net/2014/03/testable-apis-with-node-dot-js</id>
    <content type="html"><![CDATA[<p>API is heart of modern web application. It&rsquo;s all about to make it easy to consume, scale and make sure it works as expected. Currently I follow &ldquo;all open API methods must have tests&rdquo; (AOAMMHT) principle. I used to work with .NET technologies, where testing of API&rsquo;s was about calling methods of corresponding controller object, which typically was unit testing &ndash; mocking up all controller dependencies, setting up expects of returned values.</p>

<p>I&rsquo;ve changed my mind on testing with Node.js/Express.js development. For API&rsquo;s I prefer &ldquo;end-to-end&rdquo; testing: setting up user account, authentication, HTTP calls to server, real calls to DB and serving JSON payload back. API&rsquo;s have to be tested from consumer point of few to be able to give some meaningful results.</p>

<!-- MORE -->


<h2>Tools and Frameworks</h2>

<p>Pretty standard setup: <a href="http://visionmedia.github.io/mocha/">mocha</a>, <a href="http://chaijs.com/">chai</a>, <a href="https://github.com/mikeal/request">request</a>.</p>

<p>Mocha is time proven tool for testing Node.js applications, Chai is good enough expectation framework and Request as one best HTTP clients I even worked with.</p>

<h2>Prepare application for testing</h2>

<p>Dependencies above is installed via <code>npm install</code> and should be saved to <code>package.json</code> file (with <code>--save</code> option). Your project structure should have <code>test</code> folder inside, which mocha is using as default to look tests inside. Few files should be added there, current structure I have that works.</p>

<p>```plain
/test</p>

<pre><code>/specs
    auth.spec.js
    ...
common.js
mocha.opts
utils.js
runMocha.js
</code></pre>

<p>```</p>

<p><code>/api</code> folder is the one that would contain specifications for you API, <code>mocha.opts</code> &ndash; contains global mocha configuration, <code>common.js</code> is common require file, that all tests are using, <code>utils.js</code> &ndash; test helper that would contain everything you need during testing, <code>runMocha.js</code> utility that would be tests entry point.</p>

<h3>mocha.opts</h3>

<p><code>plain
--require ./test/common.js
--reporter spec
--ui bdd
--recursive
--colors
--timeout 60000
--slow 300
</code></p>

<p>Mocha options allow to require some additional javascript file, as well as setting up global Mocha settings as what reporter to use, timeouts etc.</p>

<h3>common.js</h3>

<p><code>js
global.chai = require('chai');
global.expect = global.chai.expect;
</code></p>

<p>To do not require <code>chai</code> in each spec files, it&rsquo;s possible to require it once and place to global scope.</p>

<h3>runMocha.js</h3>

<p>```js
process.env.NODE_ENV = process.env.NODE_ENV || &lsquo;test&rsquo;;
process.env.TEST_ENV = process.env.TEST_ENV || &lsquo;test&rsquo;;</p>

<p>var exit = process.exit;
process.exit = function (code) {</p>

<pre><code>setTimeout(function () {
    exit();
}, 200);
</code></pre>

<p>};</p>

<p>require(&lsquo;../source/server&rsquo;);
require(&lsquo;../node_modules/mocha/bin/_mocha&rsquo;);
```</p>

<p>The secret sauce is last 2 lines. Since <code>require</code> is synchronous we first &ldquo;call&rdquo; API server to get up and after that &ldquo;call&rdquo; mocha engine to start testing. So, inside each tests we can do real HTTP calls to real HTTP servers. No mocks.</p>

<h3>package.json</h3>

<p>```js
// &hellip;
&ldquo;scripts&rdquo;: {</p>

<pre><code>"test": "node test/runMocha",
</code></pre>

<p>  },
// &hellip;
```</p>

<p>Package file should contain script to call API tests with simple <code>npm test</code> command.</p>

<h2>Test driven API</h2>

<p>Mocha is using BDD (behaviour driven development) approach to testing. Comparing to classical TDD, BDD encourage to write specifications in plain English, which works good especially when you just starting with particular feature.</p>

<p>What I typically do is just writing down specification of API, without any thinking of how to implement it. Give you example of something that I worked with recently.</p>

<p>```js
var request = require(&lsquo;request&rsquo;);
var testUtils = require(&lsquo;../utils&rsquo;);</p>

<p>describe(&lsquo;collections.spec.js&rsquo;, function () {</p>

<pre><code>describe('when non authorized', function () {
    it ('should not be authorized', function () {
    });
});

describe('when authorized', function () {
    describe('when new collection created', function () {
        describe('public', function () {
            it('should respond with 201 (created)', function () {
            });

            it('should create new collection', function () {
            });

            it('should have user', function () {
            });

            it('should collection be public', function () {
            });

            describe('and title is missing', function () {
                it('should respond with 412 (bad request)', function () {
                });
            });

            describe('with description', function () {
                it('should respond with 201 (created)', function () {
                });

                it('should create new collection', function () {
                });
            });
        });
    });

    // etc..
});
</code></pre>

<p>});
```</p>

<p>This is kind of skeleton I to have before start anything else.</p>

<h3>Unauthorized access</h3>

<p>If your API or part of it requires authorization, I prefer to test it.</p>

<p>```js</p>

<pre><code>var token, user, url, headers, response, results;

beforeEach(function () {
    url = testUtils.getRootUrl() + '/api/collections';
});

describe('when non authorized', function () {
    beforeEach(function (done) {
        request.get({url: url, json: true}, function (err, resp, body) {
            response = resp;
            done(err);
        });
    });

    it ('should not be authorized', function () {
        expect(response.statusCode).to.equal(401);
    });
});
</code></pre>

<p>```</p>

<p><code>testUtils.getRootUrl()</code> returns qualified URL for API, depending on test environment. During development, it&rsquo;s just <code>http://localhost:3000</code> where your <code>server.js</code> started.</p>

<h3>Authorized access</h3>

<p>Authorized access typically requires some kind of <code>access_token</code> sent either by headers or query string. Doesn&rsquo;t matter how, but <code>utils.js</code> must have method that would create new user and obtain access token from API. The actual implementation of such method would depend on your API auth mechanism.</p>

<p>All tests that required authorization access, should have such <code>beforeEach()</code>,</p>

<p>```js
beforeEach(function (done) {</p>

<pre><code>testUtils.createTestUserAndLoginToApi(function (err, createdUser, accessToken) {
    token = accessToken;
    user = createdUser;
    headers = {'X-Access-Token': accessToken};
    done(err);
});
</code></pre>

<p>});
```</p>

<p>After <code>access_token</code> is acquired, it can be used as part of any authorized calls.</p>

<h3>Behavior tests</h3>

<p>Now, everything is ready to test the behavior of API. Nothing fancy here, just act as clients do. Send HTTP requests, receive responses and check HTTP statuses. I&rsquo;ll just post some code, so it would give you direction.</p>

<p>```js
describe(&lsquo;when new collection created&rsquo;, function () {</p>

<pre><code>describe('public', function () {
    beforeEach(function () {
        collection = {title: 'This is test collection', public: true};
    });

    beforeEach(function (done) {
        request.post({url: url, headers: headers, body: collection, json: true}, function (err, resp, body) {
            response = resp;
            results = body;
            done(err);
        });
    });

    it('should respond with 201 (created)', function () {
        expect(response.statusCode).to.equal(201);
    });

    it('should create new collection', function () {
        expect(results.title).to.be.ok;
        expect(results._id).to.be.ok;
    });

    it('should have user', function () {
        expect(results.user).to.equal(user.email);
    });

    it('should collection be public', function () {
        expect(results.public).to.equal(true);
    });

    describe('and title is missing', function () {
        beforeEach(function (done) {
            request.post({url: url, headers: headers, body: {}, json: true}, function (err, resp, body) {
                response = resp;
                results = body;
                done(err);
            });
        });

        it('should respond with 412 (bad request)', function () {
            expect(response.statusCode).to.equal(412);
        });
    });

    describe('with description', function () {
        beforeEach(function () {
            collection = {title: 'This is test collection', description: 'description'};
        });

        beforeEach(function (done) {
            request.post({url: url, headers: headers, body: collection, json: true}, function (err, resp, body) {
                response = resp;
                results = body;
                done(err);
            });
        });

        it('should respond with 201 (created)', function () {
            expect(response.statusCode).to.equal(201);
        });

        it('should create new collection', function () {
            expect(results.description).to.equal('description');
        });
    });
});
</code></pre>

<p>});
```</p>

<h2>Conclusions</h2>

<p>I think dynamic languages as JavaScript is great for testing API&rsquo;s. Having no types eliminates &ldquo;model-per-response&rdquo; classes, <code>request.js</code> is great for making HTTP calls and <code>mocha</code> makes specifications output looks nice. So, nevertheless of back-end technology you can try to use the approach and see how it works for you.</p>

<p>The setup of tests and starting up of API services are so lightweight in Node.js that makes test-first API development nice and pleasant thing.</p>
]]></content>
  </entry>
  
</feed>
