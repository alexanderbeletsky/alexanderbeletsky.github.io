<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: CS101 | Alexander Beletsky's development blog]]></title>
  <link href="http://alexanderbeletsky.github.io/blog/categories/cs101/atom.xml" rel="self"/>
  <link href="http://alexanderbeletsky.github.io/"/>
  <updated>2013-06-13T17:43:33+03:00</updated>
  <id>http://alexanderbeletsky.github.io/</id>
  <author>
    <name><![CDATA[Alexander Beletsky]]></name>
    <email><![CDATA[alexander.beletsky@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CS101 Course Accomplished!]]></title>
    <link href="http://alexanderbeletsky.github.io/2012/06/cs101-course-accomplished.html"/>
    <updated>2012-06-14T10:14:00+03:00</updated>
    <id>http://alexanderbeletsky.github.io/2012/06/cs101-course-accomplished</id>
    <content type="html"><![CDATA[<div class='post'>
<p>        Yesterday, I have finally received results for my Final Exams of CS101 Udacity course. I did it! <br />
    </p>    <p>        I have successfully accomplished that course, received the certificate with "High Distinction". To be honest, I thought it would be "Highest Distinction", since I was pretty sure about correctness of all my solutions posted. But reality is different, you can never be sure. Next time, I'll probably put more attention to verification of my code. Nevertheless, here is my certificate.<br />
    </p>    <a href="https://lh3.googleusercontent.com/-2wAuJhZyw98/T9mOrLPBgJI/AAAAAAAAI1I/yFPb5J7BW3c/s720/cert.png"><br />
        <img src="https://lh3.googleusercontent.com/-2wAuJhZyw98/T9mOrLPBgJI/AAAAAAAAI1I/yFPb5J7BW3c/s720/cert.png" alt="certificate" style="width: 620px"/><br />
    </a><br />
    <p>        I'm really happy that I managed to make this happen. It's probably nothing to proud for, but I feel much motivate for further Udacity courses. As I said in previous post, I enrolled for next ones on statistics and algorithms. Hope I will be able to go through them, with at least same results I got for CS101.<br />
    </p>    <p>        Once again, thanks to <a href="http://www.udacity.com/">Udacity</a> for such great opportunities.<br />
    </p></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CS101 Building a Search Engine: Week 7 and Final Exams]]></title>
    <link href="http://alexanderbeletsky.github.io/2012/06/cs101-building-search-engine-week-7-and.html"/>
    <updated>2012-06-08T22:06:00+03:00</updated>
    <id>http://alexanderbeletsky.github.io/2012/06/cs101-building-search-engine-week-7-and</id>
    <content type="html"><![CDATA[<div class='post'>
<p>As I said in my <a href="http://www.beletsky.net/2012/05/cs101-building-search-engine-week-5-and.html">previous</a> post, last several units of CS101 were a little tought. Not so difficult, but it made me a little worry what's it gonna be in final exams. Being posted right in time, I had to conclude Unit 7 before I start with exams. That time, I had some doubts if I'm able to meet course deadline.<br />
</p><p>Fortunatelly, Unit 7 was non-technical one. I went throught it rather quickly. Some scenes for this unit were taken in <a href="http://www.computerhistory.org/">Compute History Museum</a>. This place is just amazing, I wish I had a chance to visit it someday. We've been passed throught a pre-historical computers (like Babbage machine), first hard drives and other interesting stuff. Besides of that we guested Mozilla company talking to it's president and developers about open source projects, infuence of open source and some thoughts on how to be involved in open source community.<br />
</p><p>The final exam appeared to be not so difficult. I submitted it in time, even earlier than expected. I was also quite surpised, to see that deadline is a little prolonged up to 4th of June. Anyway, the solutions are submitted and now it would take up to 2 weeks waiting for results. I really looking forward and hoping to get my certificate.<br />
</p><p>Conluding this series of posts I have to say - Udacity courses are awesome! I really appreciate <a href="http://www.cs.virginia.edu/~evans/">David Evans</a> and <a href="http://robots.stanford.edu/">Sebastian Thrun</a> for making all that happen. My big credit goes to David who had lead CS101 and was just a perfect professor, clearly describe all the material and showing nice examples. I would like to say 'Thank you' for everyone envolved.<br />
</p><p>I think CS101 was great 'warm-up' course. I would not stop on that, but I already enrolled for next ones. This time I've choosen more fundametal -  <a href="http://www.udacity.com/overview/Course/st101/CourseRev/1">ST101 - Introduction to Statistics</a> and <a href="http://www.udacity.com/overview/Course/cs215/CourseRev/1">CS215 - Algorithms, Crunching Social Networks</a>. Both courses are starting June 25. Not sure, would it be possible to make them on parallel, so I might hold one if it would be to difficult. Besides of that I'm currenty looking throught <a href="http://www.udacity.com/overview/Course/cs253/CourseRev/apr2012">CS253 - Web Application Engineering</a> with <a href="http://en.wikipedia.org/wiki/Steve_Huffman">Steve Huffman</a> (the creator of <a href="http://www.reddit.com/">reddit.com</a>) just as a free course, to play a little more with Python and Google App Engine.<br />
</p><p>I highly recomend you to pickup some course today. And once again, thanks a lot to <a href="http://www.udacity.com">Udacity</a> for that priceless opportunity to learn!<br />
</p></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CS101 Building a Search Engine: Week 5 and 6]]></title>
    <link href="http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-5-and.html"/>
    <updated>2012-05-31T17:28:00+03:00</updated>
    <id>http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-5-and</id>
    <content type="html"><![CDATA[<div class='post'>
<p>        <small><strong>Disclaimer:</strong> this blog post expresses some impressions and details of Udacity CS101 "Building a Search Engine" online course. If you are either currently participating it or plan to do so in nearest future, this blog post could be a spoiler. Even though, I'm trying to make it generic as possible and do not spoil important things.<br />
        </small><br />
    </p>    <p>        With a quite delay I've concluded units 5 and 6. I'm in a big rush now, since the exam week is already started, but I've not yet completed Unit 7. Fortunately, Unit 7 is not technical one, but rather common computer science education, that helps to shape all knowledge received through seven weeks together.     <br />
    </p>    <p>        I would say that those 2 units is something where I start to feel some complexity. In Unit 5 we focused on making things faster, basically by introduction more advanced data structures for the same job. We went from a list based index implementation to self-implemented hash table and then utilized the Python dictionary type. Again, abstracting out of many simple things is what good developer should always do, but I was surprised how many things I forgot about main properties of hash functions and hash tables. We were also did a very basic algorithms analysis stuff. <br />
    </p>    <p>        Unit 6 is a real computer science. Besides of the playing with recursive algorithms we did more advanced things as graph theory. All of that was a fundamentals for implementing Pang Ranking mechanism. We used famous Google's (Larry Page's) algorithm that everybody heard of <a href="http://en.wikipedia.org/wiki/PageRank">PageRank</a>. This is where my brains start to heat. Will be honest with you, I still missing it's some parts, so it will take some time get the clear picture about it.  <br />
    </p>    <p>        So, the crawler starts to have real search engine features. Not only extracting links and indexing the keywords, that's definitely not enough for search engine. But building the links graph and computing page ranks, that then used in lookup functions to provide the best choice on search keyword. It's very simplified but working model of something that Google have (probably something that Google <a href="http://infolab.stanford.edu/~backrub/google.html">might have</a> back in 1998).  <br />
    </p>    <p>        Python. I like language more and more and start to feel some confidence. In the same time there are several things that I dislike. Not so serious, almost cosmetic.. but something that a little bugs me a little.<br />
    </p>    <p>        Anyway, I have only few days now to submit my exam works. I already glanced on exam tasks and they don't appear to much complex, so I have good chances to be in time with it. Wish me a good luck! I'll update you as soon as I got any results! <br />
    </p></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CS101 Building a Search Engine: Week 4]]></title>
    <link href="http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-4.html"/>
    <updated>2012-05-20T14:50:00+03:00</updated>
    <id>http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-4</id>
    <content type="html"><![CDATA[<div class='post'>
<p><small><strong>Disclaimer:</strong> this blog post expresses some impressions and details of Udacity CS101 "Building a Search Engine" online course. If you are either currently participating it or plan to do so in nearest future, this blog post could be a spoiler. Even though, I'm trying to make it generic as possible and do not spoil important things.<br />
</small><br />
</p><p>I've got completed Unit 4 of course during this week. It's getting more and more interesting and the crawler we building there getting more complicated. <br />
</p><p>This week we got through the basic data structures, mainly based on lists. The most interesting thing was an index data structure, thought. We've built the simple page indexer. Now the result of crawling is not simply the list of crawled links, but instead is index that keeps track of content (as word) and the URL where the word is mention. If some of you don't know what the index is, the simplest explanation is get just to open any technical book. At the end of the book you will see "Index" section. By looking for information you have to option. Either go from one page to another, finding keyword appearance.. or go to index and see exact pages, where this keyword is mentioned. Indices are essential for quick search of data.<br />
</p><p>The index that my crawler produce, crawling the <a href="http://www.udacity.com/cs101x/index.html">test page</a> is:<br />
</p><pre class="brush: python">[['This', ['http://www.udacity.com/cs101x/index.html']], 
   ['is', ['http://www.udacity.com/cs101x/index.html']], 
   ['a', ['http://www.udacity.com/cs101x/index.html']], 
   ['test', ['http://www.udacity.com/cs101x/index.html']], 
   ['page', ['http://www.udacity.com/cs101x/index.html']], 
   ['for', ['http://www.udacity.com/cs101x/index.html']], 
   ['learning', ['http://www.udacity.com/cs101x/index.html']], 
   ['to', ['http://www.udacity.com/cs101x/index.html', 'http://www.udacity.com/cs101x/crawling.html']], 
   ['crawl!', ['http://www.udacity.com/cs101x/index.html']]
   # ...
    </pre><p>I went a little above the given task and improved the crawler with "clean-up html tags" functionality. So, I get the body part of document, strip out all HTML tags and then index the content. The latest version of crawler is in this <a href="https://gist.github.com/2757731">gist</a>.<br />
</p><p>We also looked on some Internet fundamentals as: bandwidth, latency, traceroutes and protocols. <br />
</p><p>I haven't yet started any project on python except the crawler one. With implementing the of more complex applications I start to feel the lack of IDE with debugger. I currently use Sublime Text 2 + print statement as my IDE and debugger tool. It might be time to look for something better.<br />
</p><p>Everything is going fine so far, except the fact I'm being late for one week. The final exam is going to be posted at 27th of May and it will take one week to have a change to pass it. So, I've got a goal to complete 2 units through this week. The half of course is done! <br />
</p></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CS101 Building a Search Engine: Week 3]]></title>
    <link href="http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-3.html"/>
    <updated>2012-05-07T12:58:00+03:00</updated>
    <id>http://alexanderbeletsky.github.io/2012/05/cs101-building-search-engine-week-3</id>
    <content type="html"><![CDATA[<div class='post'>
<p><small><strong>Disclaimer:</strong> this blog post expresses some impressions and details of Udacity CS101 "Building a Search Engine" online course. If you are either currently participating it or plan to do so in nearest future, this blog post could be a spoiler. Even though, I'm trying to make it generic as possible and do not spoil important things.<br />
</small><br />
</p><p>Yesterday, I've concluded Unit 3 of <a href="http://www.udacity.com/">CS101 Building Search Engine</a> class. I had a little lag, since I've been to little vacation at the beginning of previous week, so got a chance to get back to class only Thursday. So, I still have one homework task in my to-do list.<br />
</p><p>It's been an interesting unit, through it's still very basic one. I'm little more confident with Python, getting powered by knowledge of collections, indexes etc. Again, I'm really pleased with language simplicity. Just few code snippets I like,<br />
</p><pre class="brush: python"># creates generic list
        some_list = []
        
        # add something inside
        some_list.append(1)
        some_list.append('z')
        some_list.append([3,2,1])
        
        # iterate by for loop
        for e in some_list:
            pass
            
        # or with while
        while some_list:
            e = some_list.pop()
        
        # get index of element
        index = some_list.index(1)
    </pre><p>I also started to familiarize with functional style of Python programming. You can find some good inputs <a href="http://docs.python.org/howto/functional.html">here</a>. Everything look very interesting so far.<br />
</p><p>This week we moved further with "real" implementation of web crawler. Instead of going by the set of quizzes I went my own path and created my implementation of simple crawler. So, what it does currently is go from 'seed' page and collect all links it's able to find on target pages and related pages. I went a little far, since I made it run on real web requests, instead of test data that current unit supposes. If you are interested code could be found <a href="https://gist.github.com/2626946">here</a>.<br />
</p><p>Still I pretend as CS101 student trying to apply only knowledge I got through latest weeks. It's great exercise I believe, showing some gaps in my education or concept understanding.  <br />
</p><p>Homework was interesting as well. <a href="http://www.crunchbase.com/person/anna-patterson">Anna Patterson</a> was a starring guest for homework session. Together with Anna we tried to improve crawler with some real life requirements, like max_pages and max_depth parameter to prevent crawler to stay in indefinite loop. Anna is great expert in this field, so for each homework task I highly recommend to check the answer, a lot of interesting details there.<br />
</p></div>

]]></content>
  </entry>
  
</feed>
